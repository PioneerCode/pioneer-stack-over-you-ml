{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017 Stack Overflow Developer Survey MultiClass Classification (SciKit Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, neighbors, svm, ensemble, tree, neural_network, naive_bayes\n",
    "\n",
    "sys.path.insert(0,os.path.join(os.getcwd(), os.pardir,  'src', 'data'))\n",
    "import stack_data\n",
    "\n",
    "SHOW_DISPLAY = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51392, 8)\n"
     ]
    }
   ],
   "source": [
    " # Fetch the data\n",
    "raw_data = stack_data.get_data()\n",
    "\n",
    "print(raw_data.shape)\n",
    "if SHOW_DISPLAY:\n",
    "    display(raw_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36125, 8)\n"
     ]
    }
   ],
   "source": [
    "# Remove all rows with no label values\n",
    "raw_data = raw_data.dropna(subset=[stack_data.LABEL_NAME], how='all')\n",
    "\n",
    "print(raw_data.shape)\n",
    "if SHOW_DISPLAY:\n",
    "    display(raw_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16747, 8)\n"
     ]
    }
   ],
   "source": [
    "# Iterate all rows and drop ones with MultiLabel, effectively\n",
    "# turning this into a MultiClass problem.\n",
    "expanded_data = []\n",
    "for (idx, row) in raw_data.iterrows():\n",
    "    # Check for delimiter\n",
    "    split = [x.strip() for x in row.loc[stack_data.LABEL_NAME].split(';')]\n",
    "    if len(split) is 1:\n",
    "        expanded_data.append(row)\n",
    "        \n",
    "raw_data = pd.DataFrame(expanded_data).reset_index(drop=True)\n",
    "\n",
    "print(raw_data.shape)\n",
    "if SHOW_DISPLAY:\n",
    "    display(raw_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16747, 8)\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "def label_encode(df, columns):\n",
    "    for col in columns:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        col_values_unique = list(df[col].unique())\n",
    "        le_fitted = le.fit(col_values_unique)\n",
    " \n",
    "        col_values = list(df[col].values)\n",
    "        le.classes_\n",
    "        col_values_transformed = le.transform(col_values)\n",
    "        df[col] = col_values_transformed\n",
    " \n",
    "to_be_encoded_cols = raw_data.columns.values\n",
    "label_encode(raw_data, to_be_encoded_cols)\n",
    "\n",
    "print(raw_data.shape)\n",
    "if SHOW_DISPLAY:\n",
    "    display(raw_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to train and test data.\n",
    "# TODO: Consider cross validation\n",
    "# https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "train, test = train_test_split(raw_data, train_size = 0.8, test_size = 0.2)\n",
    "if SHOW_DISPLAY:\n",
    "    display(train.head())\n",
    "    display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Assign the DataFrame's labels (the right-most column) to train_label.\n",
    "# 2. Delete (pop) the labels from the DataFrame.\n",
    "# 3. Assign the remainder of the DataFrame to train_features\n",
    "X_train, Y_train = train, train.pop(stack_data.LABEL_NAME)\n",
    "X_test, Y_test = test, test.pop(stack_data.LABEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to iterate approach\n",
    "dict_classifiers = {\n",
    "    \"Logistic Regression\": linear_model.LogisticRegression(),\n",
    "    \"Nearest Neighbors\": neighbors.KNeighborsClassifier(),\n",
    "    \"Linear SVM\": svm.SVC(),\n",
    "    \"Gradient Boosting Classifier\": ensemble.GradientBoostingClassifier(),\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest\": ensemble.RandomForestClassifier(n_estimators = 18),\n",
    "    \"Neural Net\": neural_network.MLPClassifier(alpha = 1),\n",
    "    \"Naive Bayes\": naive_bayes.GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch process classification function\n",
    "no_classifiers = len(dict_classifiers.keys())\n",
    "def batch_classify(X_train, Y_train, X_test, Y_test, verbose = True):\n",
    "    df_results = pd.DataFrame(data=np.zeros(shape=(no_classifiers,4)), columns = ['classifier', 'train_score', 'test_score', 'training_time'])\n",
    "    count = 0\n",
    "    for key, classifier in dict_classifiers.items():\n",
    "        t_start = time.clock()\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        t_end = time.clock()\n",
    "        t_diff = t_end - t_start\n",
    "        train_score = classifier.score(X_train, Y_train)\n",
    "        test_score = classifier.score(X_test, Y_test)\n",
    "        df_results.loc[count,'classifier'] = key\n",
    "        df_results.loc[count,'train_score'] = train_score\n",
    "        df_results.loc[count,'test_score'] = test_score\n",
    "        df_results.loc[count,'training_time'] = t_diff\n",
    "        if verbose:\n",
    "            print(\"trained {c} in {f:.2f} s\".format(c=key, f=t_diff))\n",
    "        count+=1\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Logistic Regression in 0.47 s\n",
      "trained Nearest Neighbors in 0.01 s\n",
      "trained Linear SVM in 21.71 s\n",
      "trained Gradient Boosting Classifier in 9.00 s\n",
      "trained Decision Tree in 0.02 s\n",
      "trained Random Forest in 0.15 s\n",
      "trained Neural Net in 0.66 s\n",
      "trained Naive Bayes in 0.01 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.645667</td>\n",
       "      <td>0.643582</td>\n",
       "      <td>8.998906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.636784</td>\n",
       "      <td>0.642388</td>\n",
       "      <td>0.473581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>0.636784</td>\n",
       "      <td>0.642388</td>\n",
       "      <td>0.664642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.636784</td>\n",
       "      <td>0.642388</td>\n",
       "      <td>0.005346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.655296</td>\n",
       "      <td>0.639701</td>\n",
       "      <td>21.705156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840935</td>\n",
       "      <td>0.568358</td>\n",
       "      <td>0.152223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nearest Neighbors</td>\n",
       "      <td>0.649026</td>\n",
       "      <td>0.564179</td>\n",
       "      <td>0.013094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.846160</td>\n",
       "      <td>0.483881</td>\n",
       "      <td>0.018688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     classifier  train_score  test_score  training_time\n",
       "3  Gradient Boosting Classifier     0.645667    0.643582       8.998906\n",
       "0           Logistic Regression     0.636784    0.642388       0.473581\n",
       "6                    Neural Net     0.636784    0.642388       0.664642\n",
       "7                   Naive Bayes     0.636784    0.642388       0.005346\n",
       "2                    Linear SVM     0.655296    0.639701      21.705156\n",
       "5                 Random Forest     0.840935    0.568358       0.152223\n",
       "1             Nearest Neighbors     0.649026    0.564179       0.013094\n",
       "4                 Decision Tree     0.846160    0.483881       0.018688"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run classification sequence\n",
    "df_results = batch_classify(X_train, Y_train, X_test, Y_test)\n",
    "display(df_results.sort_values(by='test_score', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
